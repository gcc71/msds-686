{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcc71/msds-686/blob/main/Deep_Learning__Hello_MNIST_Moore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1BMmhrW4-VF"
      },
      "source": [
        "# A tutorial introduction into deep learning with Keras and Tensorflow.  We will use the MNIST dataset which is the 'Hello world' problem of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfjjxqk-4-VY"
      },
      "source": [
        "I always like to start my jupyter notebooks with this code because it fits the display window to my screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oq3zQaj94-Vf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "db15cc17-b4ca-4a38-bb83-ce2d8e374b98"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:95% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTIiJaMH4-We"
      },
      "source": [
        "### This tutorial was adapted from Deep Learning with Python Chollet, F. (2021). Deep Learning with Python (2nd ed.). Greenwich, CT, USA: Manning Publications Co."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7J8caRE4-Wv"
      },
      "source": [
        "Start with some definitions.\n",
        "Numerical data in an array are called [tensors](https://en.wikipedia.org/wiki/Tensor)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYhqLSfB4-W5"
      },
      "source": [
        "Scalars are 0-dimensional tensors (a single digit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sq1dfmTjXx1r",
        "outputId": "414b3697-dcac-48b5-bad3-68dec5fd598e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x is 12\n",
            "The dimension of this tensor is 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 0 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd6j127g4-Xg"
      },
      "source": [
        "A 1-dimensional tensor is also called a vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_iWxjAcgYF2H",
        "outputId": "bf9cdede-10de-4286-a79e-07a62bb8242d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x is [12  1  2  3]\n",
            "The dimention of this tensor is 1\n"
          ]
        }
      ],
      "source": [
        "x = np.array([12, 1, 2, 3]) #create a vector\n",
        "print('The value of x is', x)\n",
        "print('The dimention of this tensor is', x.ndim) # 1 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZnkKqX74-YS"
      },
      "source": [
        "A 2-dimensional tensor is also called a matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kw6vcniRYMga",
        "outputId": "5b54de29-6e91-44e8-ddfb-343324808a74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x is [[12  1  2  3]\n",
            " [ 5  6  7  8]\n",
            " [10 11 12 12]]\n",
            "The dimension of this tensor is 2\n"
          ]
        }
      ],
      "source": [
        "x = np.array([[12, 1, 2, 3],\n",
        "              [5, 6, 7, 8,],\n",
        "              [10, 11, 12, 12]])\n",
        "print('The value of x is', x) # Print the 3 x 4 matrix\n",
        "print('The dimension of this tensor is', x.ndim) # 2 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDXBkNgF4-ZH"
      },
      "source": [
        "We can create n-dimensional tensors easily, although they become difficult to visualize.\n",
        "This 3D tensor is like a cube of data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7unoEvdhYbYR",
        "outputId": "d0d46188-eaea-464e-8e77-dd7ae4b2f3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x is [[[12  1  2  3]\n",
            "  [ 5  6  7  8]\n",
            "  [10 11 12 12]]\n",
            "\n",
            " [[ 2  2  2  2]\n",
            "  [ 3  3  3  3]\n",
            "  [ 4  4  4  4]]\n",
            "\n",
            " [[ 5  5  5  5]\n",
            "  [ 6  6  6  6]\n",
            "  [ 7  7  7  7]]]\n",
            "The dimension of this tensor is 3\n"
          ]
        }
      ],
      "source": [
        "x = np.array([[[12, 1, 2, 3],\n",
        "               [5, 6, 7, 8,],\n",
        "               [10, 11, 12, 12]],\n",
        "              [[2, 2, 2, 2,],\n",
        "               [3,3,3,3],\n",
        "               [4,4,4,4]],\n",
        "              [[5,5,5,5],\n",
        "               [6,6,6,6],\n",
        "               [7,7,7,7]]])\n",
        "print('The value of x is', x)\n",
        "print('The dimension of this tensor is', x.ndim) # 3 dimensional array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QrNkyOM4-Z0"
      },
      "source": [
        "#### Reshaping tensors is an important concept to understand.  We can reshape a tensor as long as it has the same number of elements as the initial tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x5jul5ly4-Z6",
        "outputId": "e45504b7-7fe4-4961-b4b3-69598151726c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12]\n",
            " [ 1]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [ 5]\n",
            " [ 6]\n",
            " [ 7]\n",
            " [ 8]\n",
            " [10]\n",
            " [11]\n",
            " [12]\n",
            " [12]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 3]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 4]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 5]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 6]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]\n",
            " [ 7]]\n",
            "[[12  1  2  3  5  6  7  8 10]\n",
            " [11 12 12  2  2  2  2  3  3]\n",
            " [ 3  3  4  4  4  4  5  5  5]\n",
            " [ 5  6  6  6  6  7  7  7  7]]\n",
            "[[12  1  2  3  5  6  7  8 10 11 12 12  2  2  2  2  3  3]\n",
            " [ 3  3  4  4  4  4  5  5  5  5  6  6  6  6  7  7  7  7]]\n"
          ]
        }
      ],
      "source": [
        "x = x.reshape(3*3*4,1)\n",
        "print(x)\n",
        "x = x.reshape(4, 3*3)\n",
        "print(x)\n",
        "x = x.reshape(2, 18)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihVQabEo4-aS"
      },
      "source": [
        "##### Tensors have three attributes:\n",
        "- Number of axes (dimensions)\n",
        "- Shape (length of each axis)\n",
        "- Data type (typically we will use `float32`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2vP9ckYvLuh"
      },
      "source": [
        "We can also manipulate tensors with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0XE9M6y1vULu"
      },
      "outputs": [],
      "source": [
        "# Import Tensorflow as tf\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "diW1WriOvbms",
        "outputId": "7b0cf54c-fcbd-4337-fda9-43aeee4bf186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1.]\n",
            " [1.]], shape=(2, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.ones(shape=(2,1))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZMv_KG8pv6iq",
        "outputId": "a46c3dcf-1330-4815-81ec-66d8589762c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[-0.4444327],\n",
            "       [-1.2642043],\n",
            "       [ 0.7266409]], dtype=float32)>\n"
          ]
        }
      ],
      "source": [
        "# Create a Tensorflow variable\n",
        "v = tf.Variable(initial_value=tf.random.normal(shape=(3,1)))\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iljsFGcewSIE",
        "outputId": "e115898c-44e7-447d-9fbf-f0677f3f5c47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'UnreadVariable' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[0.59436387],\n",
            "       [0.3526739 ],\n",
            "       [0.06494465]], dtype=float32)>\n"
          ]
        }
      ],
      "source": [
        "# Once the variable is created it can be modified using assign\n",
        "v2 = v.assign(tf.random.normal(shape=(3,1)))\n",
        "print(v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FGkCIydvw2Ks",
        "outputId": "6d4eae32-b8a8-49c5-a134-4401ee17d629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7f70adf26429>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now we can perform some math operations on the tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (3,1) and (3,1) not aligned: 1 (dim 1) != 3 (dim 0)"
          ]
        }
      ],
      "source": [
        "# Now we can perform some math operations on the tensors\n",
        "np.dot(v, v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xdzH71UFxQ2Q",
        "outputId": "1ff66d24-8fda-40d2-f3c8-e928c326ed5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "(3, 1)\n"
          ]
        }
      ],
      "source": [
        "# We get the above error because the shapes of v and v2 do not align properly for a dot product.\n",
        "print(v.shape)\n",
        "print(v2.shape)\n",
        "\n",
        "# For a dot product to alight the column rows of X must match the rows of Y. (See Figure 2.5 in book)\n",
        "# Therefore, we must transpose v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uSctb3a0x8l-",
        "outputId": "38029e25-9b5a-43c7-9e22-771f5b7c65c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "(1, 3)\n"
          ]
        }
      ],
      "source": [
        "v3 = np.transpose(v2)\n",
        "print(v.shape)\n",
        "print(v3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l560ng4tyOdG",
        "outputId": "8c311dfb-8adb-4d25-8763-09f539fd3061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3532684 , 0.20961662, 0.03860075],\n",
              "       [0.20961662, 0.12437887, 0.02290428],\n",
              "       [0.03860075, 0.02290428, 0.00421781]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Now the rows of v match the columns of v3 we can take the dot product\n",
        "np.dot(v, v3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUA1N4pS4-aY"
      },
      "source": [
        "# Let's build our first neural net\n",
        "\n",
        "Load the MNIST library which is part of [Keras](https://keras.io/datasets/).  MNIST stands for [Modified National Institute of Standards and Technology](https://en.wikipedia.org/wiki/MNIST_database). It is a collection of 60,000 training and 10,000 test images of the digits 0-9. We will build a deep learning nerual net model to classify the 10 digits. This is the 'Hello World' problem of deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1AG-iMB8P3DZ"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5Efu6_zaQKtQ",
        "outputId": "e18c0002-cfce-45b1-b43b-ac7f3bd10d54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZYu3aOo4Qn9R",
        "outputId": "f114a3ab-e31d-46ee-918e-674b24ba6831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_images.shape #60,000 images that are 28 pixles by 28 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "73Jt87YRZBXe",
        "outputId": "eb9569e4-4abc-456e-f5f9-3d98cf2b114f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "train_images.ndim #3D tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "q_fgMe2h4-bm",
        "outputId": "5885827c-0ad8-4f4b-bbf0-5297f594d345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum value in the array is 255\n",
            "The minimum value in the array is 0\n"
          ]
        }
      ],
      "source": [
        "print('The maximum value in the array is', train_images.max()) # The maximum value in the array is 255\n",
        "print('The minimum value in the array is', train_images.min()) # The minimum value in the array is 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LvcS2anBQ8cd",
        "outputId": "f78aaa7d-4434-494f-eaca-ec85a3ae7c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test image shape: (10000, 28, 28)\n",
            "number of dimensions: 3\n",
            "maximum value 255\n",
            "minimum value: 0\n"
          ]
        }
      ],
      "source": [
        "# Get the shape, dimensions, max and min value of the test images\n",
        "print('test image shape:', test_images.shape)\n",
        "print('number of dimensions:', test_images.ndim)\n",
        "print('maximum value', test_images.max())\n",
        "print('minimum value:', test_images.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAWThxtY4-co"
      },
      "source": [
        "In general, the first axis in a tensor is the samples, the second axis is height, the third axis is the width, and the fourth is color channels (3 for RGB data, and 1 for black and white). So image data will typically be a 4D tensor -- `[samples, height, width, channels]`, while the MNIST data is 3D because the color channel is black and white and can thus be ignored.\n",
        "Video data will be a 5D tensor -- `[samples, frames, height, width, channels]`. By convention, time series data will be placed on the secod axis when present"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kavsqyWG4-cZ"
      },
      "source": [
        "Let's view one of the images.  We need to import matplotlib to view the digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jwEiakpiZXnf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HvYknn0hZf51",
        "outputId": "9d6c50af-5224-404e-8961-0c565c9716d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbYklEQVR4nO3df2zU9R3H8deB9ERsryulvZ4ULKigAl2G0jUq4mgoXUZAyCbqFjAEIitG7JymTkSdWSdmzOgq/rPB3ESYiUD0DxxW286tsIESxn50tOkEAi1I0l4pUhj97I+G2w6K8D3u+u4dz0fyTejd99N78/XSp1/67bc+55wTAAD9bJD1AACAKxMBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJq6yHuBcPT09OnTokNLT0+Xz+azHAQB45JxTZ2enQqGQBg268HnOgAvQoUOHlJ+fbz0GAOAyHThwQCNHjrzg8wMuQOnp6ZJ6B8/IyDCeBgDgVTgcVn5+fuTr+YUkLEDV1dV66aWX1NraqsLCQr366quaMmXKRded/We3jIwMAgQASexi30ZJyEUIGzduVEVFhVauXKlPPvlEhYWFKi0t1ZEjRxLxcgCAJJSQAK1evVqLFy/WQw89pFtuuUWvv/66rrnmGv3qV79KxMsBAJJQ3AN06tQp7dq1SyUlJf97kUGDVFJSooaGhvP27+7uVjgcjtoAAKkv7gH6/PPPdebMGeXm5kY9npubq9bW1vP2r6qqUiAQiGxcAQcAVwbzH0StrKxUR0dHZDtw4ID1SACAfhD3q+Cys7M1ePBgtbW1RT3e1tamYDB43v5+v19+vz/eYwAABri4nwGlpaVp8uTJqqmpiTzW09OjmpoaFRcXx/vlAABJKiE/B1RRUaEFCxbotttu05QpU/Tyyy+rq6tLDz30UCJeDgCQhBISoPvuu09Hjx7VM888o9bWVn31q1/V1q1bz7swAQBw5fI555z1EP8vHA4rEAioo6ODOyEAQBK61K/j5lfBAQCuTAQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETcA/Tss8/K5/NFbePHj4/3ywAAktxVifikt956qz744IP/vchVCXkZAEASS0gZrrrqKgWDwUR8agBAikjI94D27dunUCikMWPG6MEHH9T+/fsvuG93d7fC4XDUBgBIfXEPUFFRkdatW6etW7dqzZo1amlp0V133aXOzs4+96+qqlIgEIhs+fn58R4JADAA+ZxzLpEv0N7ertGjR2v16tVatGjRec93d3eru7s78nE4HFZ+fr46OjqUkZGRyNEAAAkQDocVCAQu+nU84VcHZGZm6qabblJTU1Ofz/v9fvn9/kSPAQAYYBL+c0DHjx9Xc3Oz8vLyEv1SAIAkEvcAPf7446qrq9O///1v/elPf9K9996rwYMH6/7774/3SwEAkljc/wnu4MGDuv/++3Xs2DGNGDFCd955p7Zv364RI0bE+6UAAEks7gHasGFDvD8lACAFcS84AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEwn8hHZBMduzY4XnNb37zG89r6uvrPa/Zu3ev5zWx+tnPfuZ5TSgU8rzmD3/4g+c13/ve9zyvKSoq8rwGiccZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwN2ykpI0bN8a07tFHH/W85ujRo57XOOc8r5k2bZrnNZ9//rnnNZL0+OOPx7TOq1iOQyx/pw0bNnheg8TjDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSNGv/vOf/3he85e//MXzmsWLF3teI0ldXV2e19x9992e16xYscLzmjvvvNPzmu7ubs9rJOk73/mO5zXvv/9+TK/l1W233dYvr4PE4wwIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUjRr3772996XrNo0aIETNK3GTNmeF6zceNGz2syMjI8r4lFLLNJ/Xdj0fz8fM9rFixYkIBJYIEzIACACQIEADDhOUD19fWaNWuWQqGQfD6fNm/eHPW8c07PPPOM8vLyNHToUJWUlGjfvn3xmhcAkCI8B6irq0uFhYWqrq7u8/lVq1bplVde0euvv64dO3Zo2LBhKi0t1cmTJy97WABA6vB8EUJZWZnKysr6fM45p5dffllPP/20Zs+eLUl64403lJubq82bN2v+/PmXNy0AIGXE9XtALS0tam1tVUlJSeSxQCCgoqIiNTQ09Lmmu7tb4XA4agMApL64Bqi1tVWSlJubG/V4bm5u5LlzVVVVKRAIRLZYLssEACQf86vgKisr1dHREdkOHDhgPRIAoB/ENUDBYFCS1NbWFvV4W1tb5Llz+f1+ZWRkRG0AgNQX1wAVFBQoGAyqpqYm8lg4HNaOHTtUXFwcz5cCACQ5z1fBHT9+XE1NTZGPW1patHv3bmVlZWnUqFFavny5XnjhBd14440qKCjQihUrFAqFNGfOnHjODQBIcp4DtHPnTt1zzz2RjysqKiT13p9p3bp1euKJJ9TV1aUlS5aovb1dd955p7Zu3aqrr746flMDAJKezznnrIf4f+FwWIFAQB0dHXw/aIB7+umnPa/5yU9+4nmNz+fzvKa8vNzzGkl64YUXPK8ZyO/Tm2++OaZ1//rXv+I8Sd/eeecdz2vO/owhBq5L/TpufhUcAODKRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABOefx0DUs/zzz8f07pY7mzt9/s9ryktLfW85sUXX/S8RpKGDh0a0zqvTp486XnN73//e89rPvvsM89rJCmWm+SvWLHC8xrubH1l4wwIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUhTTHt7u+c1r732Wkyv5fP5PK+J5caimzdv9rymPzU1NXle8+CDD3pes3PnTs9rYvXtb3/b85onnngiAZMglXEGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakKebUqVOe1xw9ejQBk/TtlVde8bzmyJEjntesXbvW8xpJ2rJli+c1f/vb3zyv6ezs9Lwmlpu/DhoU2/9jfve73/W8ZtiwYTG9Fq5cnAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GWmKSUtL87wmJycnpteK5Sah119/vec1sdyEsz9dd911ntdkZGR4XnPo0CHPa7Kzsz2vkaRZs2bFtA7wgjMgAIAJAgQAMOE5QPX19Zo1a5ZCoZB8Pp82b94c9fzChQvl8/mitpkzZ8ZrXgBAivAcoK6uLhUWFqq6uvqC+8ycOVOHDx+ObG+99dZlDQkASD2eL0IoKytTWVnZl+7j9/sVDAZjHgoAkPoS8j2g2tpa5eTkaNy4cVq6dKmOHTt2wX27u7sVDoejNgBA6ot7gGbOnKk33nhDNTU1evHFF1VXV6eysjKdOXOmz/2rqqoUCAQiW35+frxHAgAMQHH/OaD58+dH/jxx4kRNmjRJY8eOVW1traZPn37e/pWVlaqoqIh8HA6HiRAAXAESfhn2mDFjlJ2draampj6f9/v9ysjIiNoAAKkv4QE6ePCgjh07pry8vES/FAAgiXj+J7jjx49Hnc20tLRo9+7dysrKUlZWlp577jnNmzdPwWBQzc3NeuKJJ3TDDTeotLQ0roMDAJKb5wDt3LlT99xzT+Tjs9+/WbBggdasWaM9e/bo17/+tdrb2xUKhTRjxgz9+Mc/lt/vj9/UAICk5zlA06ZNk3Pugs+///77lzUQLk9mZqbnNefezeJSfetb3/K85ssuyb+QG264wfOa2bNne14j9d7Jw6usrCzPa/7/Yp1LFcvNSGN5HaC/cC84AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmIj7r+RG8ikqKopp3dGjR+M8SXKqr6/3vKaurs7zGp/P53nNmDFjPK8B+gtnQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GClymL774wvOaWG4sGsua+fPne14D9BfOgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFLhMpaWl1iMASYkzIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjBS7T+++/bz0CkJQ4AwIAmCBAAAATngJUVVWl22+/Xenp6crJydGcOXPU2NgYtc/JkydVXl6u4cOH69prr9W8efPU1tYW16EBAMnPU4Dq6upUXl6u7du3a9u2bTp9+rRmzJihrq6uyD6PPfaY3n33Xb399tuqq6vToUOHNHfu3LgPDgBIbp4uQti6dWvUx+vWrVNOTo527dqlqVOnqqOjQ7/85S+1fv16feMb35AkrV27VjfffLO2b9+ur3/96/GbHACQ1C7re0AdHR2SpKysLEnSrl27dPr0aZWUlET2GT9+vEaNGqWGhoY+P0d3d7fC4XDUBgBIfTEHqKenR8uXL9cdd9yhCRMmSJJaW1uVlpamzMzMqH1zc3PV2tra5+epqqpSIBCIbPn5+bGOBABIIjEHqLy8XHv37tWGDRsua4DKykp1dHREtgMHDlzW5wMAJIeYfhB12bJleu+991RfX6+RI0dGHg8Ggzp16pTa29ujzoLa2toUDAb7/Fx+v19+vz+WMQAASczTGZBzTsuWLdOmTZv04YcfqqCgIOr5yZMna8iQIaqpqYk81tjYqP3796u4uDg+EwMAUoKnM6Dy8nKtX79eW7ZsUXp6euT7OoFAQEOHDlUgENCiRYtUUVGhrKwsZWRk6JFHHlFxcTFXwAEAongK0Jo1ayRJ06ZNi3p87dq1WrhwoSTp5z//uQYNGqR58+apu7tbpaWleu211+IyLAAgdXgKkHPuovtcffXVqq6uVnV1dcxDAcmkubnZegQgKXEvOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiI6TeiAvifu+66y/OaS7mzPJDqOAMCAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1LgMk2cONHzmhtvvNHzmubm5n5ZI0kjRoyIaR3gBWdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkYKGHjqqac8r1m0aFG/vI4k/eIXv/C85pZbbonptXDl4gwIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUgBA3PnzvW8ZsOGDZ7XbNu2zfMaSXr22Wc9r1m7dq3nNcOGDfO8BqmDMyAAgAkCBAAw4SlAVVVVuv3225Wenq6cnBzNmTNHjY2NUftMmzZNPp8vanv44YfjOjQAIPl5ClBdXZ3Ky8u1fft2bdu2TadPn9aMGTPU1dUVtd/ixYt1+PDhyLZq1aq4Dg0ASH6eLkLYunVr1Mfr1q1TTk6Odu3apalTp0Yev+aaaxQMBuMzIQAgJV3W94A6OjokSVlZWVGPv/nmm8rOztaECRNUWVmpEydOXPBzdHd3KxwOR20AgNQX82XYPT09Wr58ue644w5NmDAh8vgDDzyg0aNHKxQKac+ePXryySfV2Niod955p8/PU1VVpeeeey7WMQAASSrmAJWXl2vv3r36+OOPox5fsmRJ5M8TJ05UXl6epk+frubmZo0dO/a8z1NZWamKiorIx+FwWPn5+bGOBQBIEjEFaNmyZXrvvfdUX1+vkSNHfum+RUVFkqSmpqY+A+T3++X3+2MZAwCQxDwFyDmnRx55RJs2bVJtba0KCgouumb37t2SpLy8vJgGBACkJk8BKi8v1/r167Vlyxalp6ertbVVkhQIBDR06FA1Nzdr/fr1+uY3v6nhw4drz549euyxxzR16lRNmjQpIX8BAEBy8hSgNWvWSOr9YdP/t3btWi1cuFBpaWn64IMP9PLLL6urq0v5+fmaN2+enn766bgNDABIDZ7/Ce7L5Ofnq66u7rIGAgBcGXzuYlXpZ+FwWIFAQB0dHcrIyLAeBxgwYvkZuR/96EcxvdZrr73mec1f//pXz2tuueUWz2sw8F3q13FuRgoAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpACAuOJmpACAAY0AAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJq6wHONfZW9OFw2HjSQAAsTj79ftitxodcAHq7OyUJOXn5xtPAgC4HJ2dnQoEAhd8fsDdDbunp0eHDh1Senq6fD5f1HPhcFj5+fk6cODAFX2nbI5DL45DL45DL45Dr4FwHJxz6uzsVCgU0qBBF/5Oz4A7Axo0aJBGjhz5pftkZGRc0W+wszgOvTgOvTgOvTgOvayPw5ed+ZzFRQgAABMECABgIqkC5Pf7tXLlSvn9futRTHEcenEcenEcenEceiXTcRhwFyEAAK4MSXUGBABIHQQIAGCCAAEATBAgAICJpAlQdXW1rr/+el199dUqKirSn//8Z+uR+t2zzz4rn88XtY0fP956rISrr6/XrFmzFAqF5PP5tHnz5qjnnXN65plnlJeXp6FDh6qkpET79u2zGTaBLnYcFi5ceN77Y+bMmTbDJkhVVZVuv/12paenKycnR3PmzFFjY2PUPidPnlR5ebmGDx+ua6+9VvPmzVNbW5vRxIlxKcdh2rRp570fHn74YaOJ+5YUAdq4caMqKiq0cuVKffLJJyosLFRpaamOHDliPVq/u/XWW3X48OHI9vHHH1uPlHBdXV0qLCxUdXV1n8+vWrVKr7zyil5//XXt2LFDw4YNU2lpqU6ePNnPkybWxY6DJM2cOTPq/fHWW2/144SJV1dXp/Lycm3fvl3btm3T6dOnNWPGDHV1dUX2eeyxx/Tuu+/q7bffVl1dnQ4dOqS5c+caTh1/l3IcJGnx4sVR74dVq1YZTXwBLglMmTLFlZeXRz4+c+aMC4VCrqqqynCq/rdy5UpXWFhoPYYpSW7Tpk2Rj3t6elwwGHQvvfRS5LH29nbn9/vdW2+9ZTBh/zj3ODjn3IIFC9zs2bNN5rFy5MgRJ8nV1dU553r/2w8ZMsS9/fbbkX3+8Y9/OEmuoaHBasyEO/c4OOfc3Xff7R599FG7oS7BgD8DOnXqlHbt2qWSkpLIY4MGDVJJSYkaGhoMJ7Oxb98+hUIhjRkzRg8++KD2799vPZKplpYWtba2Rr0/AoGAioqKrsj3R21trXJycjRu3DgtXbpUx44dsx4poTo6OiRJWVlZkqRdu3bp9OnTUe+H8ePHa9SoUSn9fjj3OJz15ptvKjs7WxMmTFBlZaVOnDhhMd4FDbibkZ7r888/15kzZ5Sbmxv1eG5urv75z38aTWWjqKhI69at07hx43T48GE999xzuuuuu7R3716lp6dbj2eitbVVkvp8f5x97koxc+ZMzZ07VwUFBWpubtZTTz2lsrIyNTQ0aPDgwdbjxV1PT4+WL1+uO+64QxMmTJDU+35IS0tTZmZm1L6p/H7o6zhI0gMPPKDRo0crFAppz549evLJJ9XY2Kh33nnHcNpoAz5A+J+ysrLInydNmqSioiKNHj1av/vd77Ro0SLDyTAQzJ8/P/LniRMnatKkSRo7dqxqa2s1ffp0w8kSo7y8XHv37r0ivg/6ZS50HJYsWRL588SJE5WXl6fp06erublZY8eO7e8x+zTg/wkuOztbgwcPPu8qlra2NgWDQaOpBobMzEzddNNNampqsh7FzNn3AO+P840ZM0bZ2dkp+f5YtmyZ3nvvPX300UdRv74lGAzq1KlTam9vj9o/Vd8PFzoOfSkqKpKkAfV+GPABSktL0+TJk1VTUxN5rKenRzU1NSouLjaczN7x48fV3NysvLw861HMFBQUKBgMRr0/wuGwduzYccW/Pw4ePKhjx46l1PvDOadly5Zp06ZN+vDDD1VQUBD1/OTJkzVkyJCo90NjY6P279+fUu+Hix2HvuzevVuSBtb7wfoqiEuxYcMG5/f73bp169zf//53t2TJEpeZmelaW1utR+tXP/jBD1xtba1raWlxf/zjH11JSYnLzs52R44csR4toTo7O92nn37qPv30UyfJrV692n366afus88+c84599Of/tRlZma6LVu2uD179rjZs2e7goIC98UXXxhPHl9fdhw6Ozvd448/7hoaGlxLS4v74IMP3Ne+9jV34403upMnT1qPHjdLly51gUDA1dbWusOHD0e2EydORPZ5+OGH3ahRo9yHH37odu7c6YqLi11xcbHh1PF3sePQ1NTknn/+ebdz507X0tLitmzZ4saMGeOmTp1qPHm0pAiQc869+uqrbtSoUS4tLc1NmTLFbd++3Xqkfnffffe5vLw8l5aW5q677jp33333uaamJuuxEu6jjz5yks7bFixY4JzrvRR7xYoVLjc31/n9fjd9+nTX2NhoO3QCfNlxOHHihJsxY4YbMWKEGzJkiBs9erRbvHhxyv1PWl9/f0lu7dq1kX2++OIL9/3vf9995Stfcddcc42799573eHDh+2GToCLHYf9+/e7qVOnuqysLOf3+90NN9zgfvjDH7qOjg7bwc/Br2MAAJgY8N8DAgCkJgIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxH8BB0q1GdOY6GMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "digit = train_images[4] # Select the fourth sample.\n",
        "plt.imshow(digit, cmap=plt.cm.binary) # Show the sample.  cmap is the color map.  We will keep it black and white (binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_eEPRIC9bb1"
      },
      "source": [
        "The 4th train image looks like the number 9.  Lets make sure the label matches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "srjlYOAavZUW",
        "outputId": "ea5b2334-bd09-4aad-fe70-04011fa6296c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "train_labels[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gSBcnrgsRPJ3"
      },
      "outputs": [],
      "source": [
        "# Import models and layers from the keras library\n",
        "from keras import models\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWKxgF2L9_xG"
      },
      "source": [
        "We will be working with sequential models and *dense layers*. More on what those mean later.  Another name for a dense layer is a *fully connected layer*.  The dense layer must be one-dimensional. Therefore, the input image matrix must be reshaped into a vector. There are 60,000 test images with a shape of 28 x 28. We will reshape each image into a vector of length 28 * 28 == 784.\n",
        "\n",
        "We pick the `relu` activation function for our first layer and our output layer activation function is `softmax` because we have a multiclass classification problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "w8lxhcrHRV0x"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkdeEsM8FztX"
      },
      "source": [
        "Now we compile the model.  We use the `adam` optimizer and choose `categorical_crossentropy` for the loss function because it is a multiclass classification problem. We will evaluate our model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TcixP8_xR5j7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERD4fJuF_n2l"
      },
      "source": [
        "Now the model is built and compiled we need to process the images for the model.  The images need to be reshaped into a vector of the same dimentions as the input shape above.  We also normalize the values of the images to be between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cEeckA5ESIMB",
        "outputId": "e3e59020-9674-4bc0-d459-51537bfcf1c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "scale_factor = train_images.max()\n",
        "train_images =  train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32')/scale_factor\n",
        "\n",
        "test_images =  test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32')/scale_factor\n",
        "\n",
        "print(train_images.ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bw_1wSzI4-ex",
        "outputId": "a1fdd79d-a4f0-416a-a682-63d7312a618c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train image shape: (60000, 784)\n",
            "number of dimensions: 2\n",
            "maximum value 1.0\n",
            "minimum value: 0.0\n"
          ]
        }
      ],
      "source": [
        "print('train image shape:', train_images.shape)\n",
        "print('number of dimensions:', train_images.ndim)\n",
        "print('maximum value', train_images.max())\n",
        "print('minimum value:', train_images.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "q8QVj91nADix",
        "outputId": "72592d5b-151e-4396-b635-dd53e0f9c6c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a151276ba30>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# We can always get our images back by reshaping to a matrix.\n",
        "plt.imshow(train_images.reshape((60000,28,28))[4], cmap=plt.cm.binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "zeczsZHUVDQx"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "a9u7dxrQGsi8",
        "outputId": "20acd73e-f349-493c-b4c5-55253c39a180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "# We need to convert the labels into catergorical values.\n",
        "# We can check the train lables for the 4th value to ensure\n",
        "# it is labeled as 9\n",
        "print(train_labels[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "w90ZrgWhVPC1",
        "outputId": "3b40401c-ed64-496f-9d05-5dce7a58ccea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "500/500 [==============================] - 6s 3ms/step - loss: 0.2656 - accuracy: 0.9237\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1075 - accuracy: 0.9686\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0694 - accuracy: 0.9793\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0490 - accuracy: 0.9859\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0358 - accuracy: 0.9897\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a1510667ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Batch size is how many images to process at once.\n",
        "# Epoch is how many times to repeat the analysis.\n",
        "# Each epoch performs 500 gradient updates (60,000/120 = 500)\n",
        "model.fit(train_images, train_labels, epochs = 5, batch_size = 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OHqqd_YYVdz3",
        "outputId": "5879be00-6271-4c9f-9354-762965ee915a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0639 - accuracy: 0.9791\n",
            "test_acc: 0.9790999889373779\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIRCQyZ2F24o"
      },
      "source": [
        "# Your Turn.\n",
        "# Below is your assignment\n",
        "####  Build 3 different models with a dense layer with `relu` activation.  The output layer activation must be `softmax` since we have a multiclass problem.  You will compile the three different models with different optimizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "KgHnMI6T4-f6"
      },
      "outputs": [],
      "source": [
        "model1 = models.Sequential()\n",
        "model1.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model1.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model2 = models.Sequential()\n",
        "model2.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model2.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model3 = models.Sequential()\n",
        "model3.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model3.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnUDSgXk4-gE"
      },
      "source": [
        "#### Compile your three models with three different optimizers. Page 89 - 90 of the tetbook list some different optimizers.  You can also find more optimizers and documentation here: https://keras.io/api/optimizers/\n",
        "#### Use `categorical_crossentropy` for loss since this problem is a multiclass classification problem. The metric will be `accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FhHGydeC4-gH"
      },
      "outputs": [],
      "source": [
        "model1.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model2.compile(optimizer = 'SGD',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model3.compile(optimizer='RMSprop',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7uSP2vm4-gR"
      },
      "source": [
        "#### Fit the models with epochs = 5 and  batch_size = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Y9qFLRMA4-gT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5bed69-3dc5-40ca-a364-e87f8135ac98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model 1...\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2607 - accuracy: 0.9263\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1043 - accuracy: 0.9701\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9804\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9864\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0346 - accuracy: 0.9898\n",
            "Fitting model 2...\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 1.0891 - accuracy: 0.7453\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.8720\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4134 - accuracy: 0.8908\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.3683 - accuracy: 0.8994\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.9058\n",
            "Fitting model 3...\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2605 - accuracy: 0.9237\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1074 - accuracy: 0.9690\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0702 - accuracy: 0.9785\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9853\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0374 - accuracy: 0.9885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a15101869e0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "print('Fitting model 1...')\n",
        "model1.fit(train_images, train_labels, epochs=5, batch_size=120)\n",
        "print('Fitting model 2...')\n",
        "model2.fit(train_images, train_labels, epochs=5, batch_size=120)\n",
        "print('Fitting model 3...')\n",
        "model3.fit(train_images, train_labels, epochs=5, batch_size=120)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB4RPCz54-gb"
      },
      "source": [
        "#### Test the accuracy of the model on the test images and test labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "W7V6DjwV4-gc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117b4018-71ce-4141-8b5a-a8ee92c153c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0617 - accuracy: 0.9814\n",
            "model1_test_acc: 0.9814000129699707\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3158 - accuracy: 0.9157\n",
            "model2_test_acc: 0.9157000184059143\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9807\n",
            "model3_test_acc: 0.9807000160217285\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model1.evaluate(test_images, test_labels)\n",
        "print('model1_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = model2.evaluate(test_images, test_labels)\n",
        "print('model2_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = model3.evaluate(test_images, test_labels)\n",
        "print('model3_test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbR0ds5G4-gm"
      },
      "source": [
        "# Which optimizer gave the highest accuracy? Write you answer below\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqn4SN0ka7bt"
      },
      "source": [
        "model3 gave the best accuracy with RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD5Pjrqpa36e"
      },
      "source": [
        "### Using the optimizer that gave the highest accuracy compile 3 different models with 3 hidden layers and varying units in each hidden layer.  The first  layer is given to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "BTh369rD4-gr"
      },
      "outputs": [],
      "source": [
        "h1_model = models.Sequential()\n",
        "h1_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "h1_model.add(layers.Dense(384, activation='softmax'))\n",
        "h1_model.add(layers.Dense(62, activation='softmax'))\n",
        "h1_model.add(layers.Dense(32, activation='softmax'))\n",
        "h1_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "h2_model = models.Sequential()\n",
        "h2_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "h2_model.add(layers.Dense(62, activation='relu'))\n",
        "h2_model.add(layers.Dense(32, activation='relu'))\n",
        "h2_model.add(layers.Dense(10, activation='relu'))\n",
        "\n",
        "\n",
        "h3_model = models.Sequential()\n",
        "h3_model.add(layers.Dense(512, activation='relu',input_shape=(28 * 28,)))\n",
        "h3_model.add(layers.Dense(62, activation='softmax'))\n",
        "h3_model.add(layers.Dense(32, activation='softmax'))\n",
        "h3_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h1_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhfGqBDSENza",
        "outputId": "f78c9737-cb4c-494f-9a40-efe7f16f6343"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_67 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 384)               196992    \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 62)                23870     \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 32)                2016      \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 625,128\n",
            "Trainable params: 625,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY-vLrzS4-g1"
      },
      "source": [
        "#### Complie the three models with the best optimizer from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "AvYLN-Ld4-g3"
      },
      "outputs": [],
      "source": [
        "h1_model.compile(optimizer='adam',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "h2_model.compile(optimizer='SGD',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "h3_model.compile(optimizer='RMSprop',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRMZ56yI4-hF"
      },
      "source": [
        "#### Fit the models with epochs = 5 and  batch_size = 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "wO_mcJ9x4-hI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019b5122-47a8-4964-8cee-2da34b9de0c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model h1...\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 1.7303 - accuracy: 0.2158\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 1.7201 - accuracy: 0.2168\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.7065 - accuracy: 0.2504\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 1.6480 - accuracy: 0.3061\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 1.5986 - accuracy: 0.3088\n",
            "Fitting model h2...\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 10.4956 - accuracy: 0.0904\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 10.4500 - accuracy: 0.0904\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 10.4168 - accuracy: 0.0904\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 10.4003 - accuracy: 0.0904\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 10.3883 - accuracy: 0.0904\n",
            "Fitting model h3...\n",
            "Epoch 1/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.3291 - accuracy: 0.3147\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 1.2976 - accuracy: 0.3162\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 1.2780 - accuracy: 0.3192\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 1.2657 - accuracy: 0.3245\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 1.2451 - accuracy: 0.3767\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a146aeb6290>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "print('Fitting model h1...')\n",
        "h1_model.fit(train_images, train_labels, epochs=5, batch_size=120)\n",
        "print('Fitting model h2...')\n",
        "h2_model.fit(train_images, train_labels, epochs=5, batch_size=120)\n",
        "print('Fitting model h3...')\n",
        "h3_model.fit(train_images, train_labels, epochs=5, batch_size=120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Kcmj6x4-hU"
      },
      "source": [
        "#### Test the accuracy of the 3 models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "uRUw9R5F4-ha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a182890-f04d-409b-b6c0-c23c42353403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 1.6063 - accuracy: 0.3069\n",
            "h1_model_test_acc: 0.3068999946117401\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 10.3720 - accuracy: 0.0892\n",
            "h2_model_test_acc: 0.08919999748468399\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2504 - accuracy: 0.4097\n",
            "h3_model_model_model_test_acc: 0.4097000062465668\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = h1_model.evaluate(test_images, test_labels)\n",
        "print('h1_model_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = h2_model.evaluate(test_images, test_labels)\n",
        "print('h2_model_test_acc:', test_acc)\n",
        "\n",
        "test_loss, test_acc = h3_model.evaluate(test_images, test_labels)\n",
        "print('h3_model_model_model_test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-fHqdpQ4-hm"
      },
      "source": [
        "#### Which model gave the highest accuracy? Write you answer below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY-GKvZYVgw9"
      },
      "source": [
        "model 3 was more accurate but I'm not sure why. I tried adding and subtracting layers and changing input sizes."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXt7y8glmNNM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}